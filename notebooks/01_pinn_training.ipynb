{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hbprosper/AIMS/blob/main/notebooks/01_pinn_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a829885c-8023-40b8-8a36-31a91c4c4262",
      "metadata": {
        "id": "a829885c-8023-40b8-8a36-31a91c4c4262"
      },
      "source": [
        "# PhotonOrbitSolver Training\n",
        "> African Institute of Mathematical Sciences (AIMS), Cape Town, South Africa<br>\n",
        "> Created: March 2025 Claire David, Tlotlo M. Oepeng, Harrison B. Prosper\n",
        "\n",
        "## Introduction\n",
        "This notebook trains a Physics-Informed Neural Network (PINN) [1, 2] to solve the following nonlinear ordinary differential equation (ODE):\n",
        "\n",
        "\\begin{align}\n",
        "  \\overset{\\textstyle\\cdot\\cdot}{u}  \\: + \\: u - \\: 3 \\: \\frac{u^2}{2}  & = \\: 0,\n",
        "\\end{align}\n",
        "\n",
        "This equation describes the orbit of photons in a Schwarzschild spacetime about a spherically symmetric body of mass $M$.\n",
        "\n",
        "### Notation\n",
        "Our variable of interest here is\n",
        "\n",
        "\\begin{align}\n",
        "  u & = \\: \\frac{r_s }{ r},\n",
        "\\end{align}\n",
        "\n",
        "where $r_s$ is the Schwarzschild radius is defined as $r_s = \\: \\frac{2 G M}{c^2},$ where $G$ is Newton's gravitational constant and $c$ is the speed of light in vacuum.\n",
        "\n",
        "\n",
        "If $C$ is the proper circumference of a circle centered at the center of mass,\n",
        "in a Schwarzschild spacetime, the radial coordinate $r \\equiv \\frac{C}{2\\pi}$ differs from the proper radial distance.\n",
        "\n",
        "\n",
        "The overdot here ($\\overset{\\textstyle\\cdot\\cdot}{u}$) indicates differentiation with respect to $\\phi$, the azimuthal angle in a spherical polar coordinate system, $(r, \\theta, \\phi)$. Here $\\theta$ is set to $\\pi \\, / \\, 2$ without loss of generality.\n",
        "\n",
        "\n",
        "The initial conditions are\n",
        "\\begin{align}\n",
        "u\\,(0) &= u_0 \\\\\n",
        "\\overset{\\textstyle\\cdot}{u}\\,(0) &= v_0.\n",
        "\\end{align}\n",
        "\n",
        "\n",
        "### Approach\n",
        "The ODE is solved using a PINN following the approach in [3]. The neural network is described by the function $g_\\beta(\\phi; u_0, v_0),$ where $\\beta$ are the network's trainable weights.  \n",
        "  \n",
        "We use the following Ansatz from the theory of connections (ToC) [4] that incorporates the initial conditions explicitly:\n",
        "\n",
        "\\begin{align}\n",
        "    u(\\phi; u_0, v_0)  &= u_0 + g_\\beta(\\phi; u_0, v_0) - g_\\beta(0; u_0, v_0) + \\phi \\left[ v_0 - \\dot{g}_\\beta(0; u_0, v_0) \\right], \\\\[1ex]\n",
        "    \\dot{u}(\\phi; u_0, v_0) &= v_0 + \\dot{g}_\\beta(\\phi; u_0, v_0) - \\dot{g}_\\beta(0; u_0, v_0),\n",
        "\\end{align}\n",
        "\n",
        "### References\n",
        "[1] B. Moseley, [Deep Learning in Scientific Computing (2023)](https://camlab.ethz.ch/teaching/deep-learning-in-scientific-computing-2023.html), ETH Zürich, Computational and Applied Mathematics Laboratory (CAMLab)  \n",
        "[2] S. Cuomo *et al*., *Scientific Machine Learning through Physics-Informed Neural Networks: Where we are and What's next*, [arXiv:2201.05624](https://doi.org/10.48550/arXiv.2201.05624)  \n",
        "[3] Aditi S. Krishnapriyan, Amir Gholami, Shandian Zhe, Robert M. Kirby, Michael W. Mahoney, *Characterizing possible failure modes in physics-informed neural networks*, NIPS'21: Proceedings of the 35th International Conference on Neural Information Processing Systems; [arXiv:2109.01050](https://arxiv.org/abs/2109.01050)  \n",
        "[4] D. Mortari, *The Theory of Connections: Connecting Points*, Mathematics, vol. 5, no. 57, 2017.\n",
        "\n",
        "\n",
        "## Local installation `pinn4bhoc`\n",
        "  ```bash\n",
        "      git clone https://github.com/soot-bit/pinn4bhoc\n",
        "      cd pinn4bhoc\n",
        "      pip install -e .\n",
        "  ```\n",
        "## Google Colab installation `pinn4bhoc`\n",
        "  1. Assign Colab working folder to string `COLAB_FOLDER` in notebook.\n",
        "  2. Execute cell below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls pinn4bhoc/"
      ],
      "metadata": {
        "id": "d4dBogC7ucZH",
        "outputId": "1e5e173e-b484-49b7-c8bf-9d87454d7efc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "d4dBogC7ucZH",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clone2colab.ipynb  notebooks  pinn4bhoc  pyproject.toml  README.md  runs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uninstall pinn4bhoc if installed\n",
        "%rm -rf pinn4bhoc\n",
        "%pip uninstall -y pinn4bhoc\n",
        "\n",
        "# clone pinn4bhoc\n",
        "!git clone https://github.com/soot-bit/pinn4bhoc\n",
        "%cd pinn4bhoc\n",
        "\n",
        "# install pinn4 bhoc\n",
        "%pip install -e ."
      ],
      "metadata": {
        "id": "jlWH_sJuu7Hv",
        "outputId": "c129ea57-0b41-4451-c445-f2f1e7752e7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "jlWH_sJuu7Hv",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping pinn4bhoc as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCloning into 'pinn4bhoc'...\n",
            "remote: Enumerating objects: 222, done.\u001b[K\n",
            "remote: Counting objects: 100% (222/222), done.\u001b[K\n",
            "remote: Compressing objects: 100% (163/163), done.\u001b[K\n",
            "remote: Total 222 (delta 129), reused 125 (delta 56), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (222/222), 255.58 KiB | 3.41 MiB/s, done.\n",
            "Resolving deltas: 100% (129/129), done.\n",
            "/content/pinn4bhoc\n",
            "Obtaining file:///content/pinn4bhoc\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pinn4bhoc\n",
            "  Building editable for pinn4bhoc (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pinn4bhoc: filename=pinn4bhoc-0.1.0-0.editable-py3-none-any.whl size=4709 sha256=2fa2d2e2ef5b7bf083baedc567b7ea3005a8d055527f0732c7f5cb726737047e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uqqhnznb/wheels/11/29/79/44bf54bc12b1609c3d73e9f19a907400fe89b63f221f5f0691\n",
            "Successfully built pinn4bhoc\n",
            "Installing collected packages: pinn4bhoc\n",
            "Successfully installed pinn4bhoc-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CecIm-CUNcNA",
      "metadata": {
        "id": "CecIm-CUNcNA"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "57bd86d0-9a07-4931-91bf-be1c0f702eb6",
      "metadata": {
        "id": "57bd86d0-9a07-4931-91bf-be1c0f702eb6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import importlib\n",
        "import numpy as np\n",
        "import matplotlib as mp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "# PINN library\n",
        "import pinn4bhoc.nn as mlp\n",
        "import pinn4bhoc.utils.data as dat"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OboD6tUhK5_r",
      "metadata": {
        "id": "OboD6tUhK5_r"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "730b8300-a871-4851-9faf-143acaf72bfa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "730b8300-a871-4851-9faf-143acaf72bfa",
        "outputId": "119a5b6e-c668-403f-8092-690d178d2636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "\n",
            "Save configuration to file runs/2025-11-07_2044/fcnn_sobol_config.yaml\n",
            "\n",
            "name: fcnn_sobol\n",
            "file:\n",
            "  losses: runs/2025-11-07_2044/fcnn_sobol_losses.csv\n",
            "  params: runs/2025-11-07_2044/fcnn_sobol_params.pth\n",
            "  init_params: runs/2025-11-07_2044/fcnn_sobol_init_params.pth\n",
            "  plots: runs/2025-11-07_2044/fcnn_sobol_plots.png\n",
            "dPhi: 0.1\n",
            "lower_bounds:\n",
            "- 0.0\n",
            "- 0.1\n",
            "- -1.0\n",
            "upper_bounds:\n",
            "- 0.1\n",
            "- 0.99\n",
            "- 1.0\n",
            "dataset_size_exponent: 16\n",
            "train_size: 65536\n",
            "val_size: 5000\n",
            "batch_size: 2048\n",
            "monitor_step: 2000\n",
            "delete: true\n",
            "num_steps: 5\n",
            "num_iters_per_step: 200000\n",
            "base_lr: 0.003\n",
            "gamma: 0.24\n",
            "val_cost_drop_threshold: 0.005\n",
            "num_iterations: 1000000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# Hardware\n",
        "# -----------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\\n\")\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset Configuration\n",
        "# -----------------------------\n",
        "\"\"\"\n",
        "For tests:\n",
        "n_steps                    = 5        # Number of steps with constant LR\n",
        "n_iterations_per_step      = 2000     # Training iterations per LR step\n",
        "monitor_every_n_iterations = 200      # Frequency of logging/monitoring\n",
        "\"\"\"\n",
        "\n",
        "name = 'fcnn_sobol'\n",
        "\n",
        "# choose whether to create or load a configuration file\n",
        "load_existing_config = False\n",
        "\n",
        "if load_existing_config:\n",
        "    config = mlp.Config(f'{name}.yaml')\n",
        "else:\n",
        "    # create new configuration\n",
        "    config = mlp.Config(name)\n",
        "\n",
        "    # Phi segement size\n",
        "    config('dPhi', 0.1)\n",
        "\n",
        "    # Bounds\n",
        "    #                       Phi     u0    v0\n",
        "    config('lower_bounds', [0.0,  0.10, -1.0])\n",
        "    config('upper_bounds', [config('dPhi'), 0.99,  1.0])\n",
        "\n",
        "    # training configuration\n",
        "    # -----------------------------------------\n",
        "    config('dataset_size_exponent', 16)\n",
        "    config('train_size', 2**config('dataset_size_exponent'))\n",
        "    config('val_size',     5000)  # validation sample size\n",
        "    config('batch_size',   2048)  #\n",
        "    config('monitor_step', 2000)  # monitor training every n (=10) iterations\n",
        "    config('delete', True)        # delete losses file before training, if True\n",
        "\n",
        "    # optimizer / scheduler configuration\n",
        "    # -----------------------------------------\n",
        "    # a step comprises a given number of iterations\n",
        "    config('num_steps', 5)        # number of training steps\n",
        "    config('num_iters_per_step', 200_000)\n",
        "    config('base_lr', 3e-3)       # initial learning rate\n",
        "    config('gamma', 0.24)         # learning rate scale factor\n",
        "\n",
        "    config('val_cost_drop_threshold', 0.005)\n",
        "    print(f'\\nSave configuration to file {config.cfg_filename}\\n')\n",
        "\n",
        "    config.save()\n",
        "\n",
        "# Total number of iterations\n",
        "config('num_iterations', config('num_iters_per_step') * config('num_steps'))\n",
        "\n",
        "print(config)\n",
        "\n",
        "# -----------------------------\n",
        "# Live Plotting Options\n",
        "# -----------------------------\n",
        "live_display  = False    # to plot cost evolution during training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ewiPspCPRwv",
      "metadata": {
        "id": "8ewiPspCPRwv"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "XibYYt5iPVPY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XibYYt5iPVPY",
        "outputId": "5f403719-6e7f-42a9-b604-3445e6559bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  SobolSample\n",
            "  65536 Sobol points created.\n",
            "\n",
            "  UniformSample\n",
            "  5000 uniformly sampled points created.\n",
            "\n",
            "===> Creating: train_dataset\n",
            "  Type               : Dataset\n",
            "  Shape of phi_vals  : torch.Size([65536, 1])\n",
            "  Shape of init_conds: torch.Size([65536, 2])\n",
            "\n",
            "===> Creating: train_valsize_dataset\n",
            "  Type               : Dataset\n",
            "  Shape of phi_vals  : torch.Size([5000, 1])\n",
            "  Shape of init_conds: torch.Size([5000, 2])\n",
            "\n",
            "===> Creating: val_dataset\n",
            "  Type               : Dataset\n",
            "  Shape of phi_vals  : torch.Size([5000, 1])\n",
            "  Shape of init_conds: torch.Size([5000, 2])\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# Point Generation\n",
        "# -----------------------------\n",
        "# Training data\n",
        "sampling_strategy = 'sobol'\n",
        "\n",
        "if sampling_strategy.lower() == \"sobol\":\n",
        "    data_train = dat.SobolSample(config('lower_bounds'),\n",
        "                                  config('upper_bounds'),\n",
        "                                  num_points_exp=config('dataset_size_exponent')\n",
        "    )\n",
        "elif sampling_strategy.lower() == \"uniform\":\n",
        "    data_train = dat.UniformSample(config('lower_bounds'),\n",
        "                                   config('upper_bounds'),\n",
        "                                   num_points=2**config('dataset_size_exponent')\n",
        "    )\n",
        "else:\n",
        "    raise ValueError(\"sampling_strategy must be one of: sobol, uniform\")\n",
        "print()\n",
        "\n",
        "# Validation data\n",
        "data_val = dat.UniformSample(config('lower_bounds'),\n",
        "                             config('upper_bounds'),\n",
        "                             num_points=config('val_size')\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# PINN Datasets\n",
        "# -----------------------------\n",
        "# Dataset for training: full tensorized subset from the raw sampling\n",
        "print('\\n===> Creating: train_dataset')\n",
        "train_dataset = dat.Dataset(data_train,\n",
        "                            start=0, end=config('train_size'),\n",
        "                            verbose=1,\n",
        "                            device=device\n",
        ")\n",
        "\n",
        "# Training subset of same size as validation dataset\n",
        "print('\\n===> Creating: train_valsize_dataset')\n",
        "train_valsize_dataset = dat.Dataset(data_train,\n",
        "                                    start=0, end=config('train_size'),\n",
        "                                    random_sample_size=config('val_size'),\n",
        "                                    verbose=1,\n",
        "                                    device=device\n",
        ")\n",
        "\n",
        "# Dataset for validation: tensorized points from the raw uniform sampling\n",
        "print('\\n===> Creating: val_dataset')\n",
        "val_dataset = dat.Dataset(data_val,\n",
        "                          start=0, end=config('val_size'),\n",
        "                          verbose=1,\n",
        "                          device=device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q12D1HKLToBI",
      "metadata": {
        "id": "Q12D1HKLToBI"
      },
      "source": [
        "# DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "O8nhS9wFV_LB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8nhS9wFV_LB",
        "outputId": "29e73663-057b-46e7-e17d-e8e5c5146d5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===> Creating: train_loader\n",
            "DataLoader\n",
            "  Number of iterations has been specified\n",
            "  maxiter:         1000000\n",
            "  batch_size:         2048\n",
            "  shuffle_step:         32\n",
            "\n",
            "\n",
            "===> Creating: val_loader\n",
            "DataLoader\n",
            "  maxiter:               1\n",
            "  batch_size:         5000\n",
            "  shuffle_step:          1\n",
            "\n",
            "\n",
            "===> Creating: train_valsize_loader\n",
            "DataLoader\n",
            "  maxiter:               1\n",
            "  batch_size:         5000\n",
            "  shuffle_step:          1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Loader for main training batches\n",
        "print('\\n===> Creating: train_loader')\n",
        "train_loader = dat.DataLoader(train_dataset,\n",
        "                              batch_size=config('batch_size'),\n",
        "                              num_iterations=config('num_iterations'),\n",
        "                              shuffle=True\n",
        ")\n",
        "\n",
        "# Loader for evaluating validation cost (single batch of val_size)\n",
        "print('\\n===> Creating: val_loader')\n",
        "val_loader = dat.DataLoader(val_dataset,\n",
        "                            batch_size=config('val_size')\n",
        ")\n",
        "\n",
        "# Loader for evaluating training cost with val-sized batch\n",
        "print('\\n===> Creating: train_valsize_loader')\n",
        "train_valsize_loader = dat.DataLoader(train_valsize_dataset,\n",
        "                                      batch_size=config('val_size')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ChCe8UIW3_c",
      "metadata": {
        "id": "9ChCe8UIW3_c"
      },
      "source": [
        "## Model, Solution, Objective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "CTn-yb_DW42a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTn-yb_DW42a",
        "outputId": "09483db7-e53c-4d37-9dca-39dd82bedbae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===> Creating model...\n",
            "\n",
            "FCNN(\n",
            "  (model): ModuleList(\n",
            "    (0): Linear(in_features=3, out_features=75, bias=True)\n",
            "    (1): Sin()\n",
            "    (2): Linear(in_features=75, out_features=75, bias=True)\n",
            "    (3): Sin()\n",
            "    (4): Linear(in_features=75, out_features=75, bias=True)\n",
            "    (5): Sin()\n",
            "  )\n",
            "  (output_layer): Linear(in_features=75, out_features=1, bias=True)\n",
            ")\n",
            "Number of parameters: 11776\n",
            "\n",
            "===> Saved initial model weights to:\n",
            "\truns/2025-11-07_2044/fcnn_sobol_init_params.pth\n"
          ]
        }
      ],
      "source": [
        "# Model Instantiation\n",
        "print('\\n===> Creating model...\\n')\n",
        "\n",
        "fcnn_model = mlp.FCNN().to(device)\n",
        "pinn_soln  = mlp.Solution(fcnn_model).to(device)\n",
        "pinn_obj   = mlp.Objective(pinn_soln).to(device)\n",
        "\n",
        "print(fcnn_model)\n",
        "print(f'Number of parameters: {mlp.count_trainable_parameters(fcnn_model)}')\n",
        "\n",
        "# Save model with initial weights\n",
        "init_model_filename = config('file/init_params')\n",
        "fcnn_model.save(init_model_filename)\n",
        "\n",
        "print(f\"\\n===> Saved initial model weights to:\\n\\t{init_model_filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92qpdDruZBBa",
      "metadata": {
        "id": "92qpdDruZBBa"
      },
      "source": [
        "# Scheduler\n",
        "Using a multistep scheduler parametrized with $\\gamma$ (initially 0.24).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "uHJxWZ3JZDNn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHJxWZ3JZDNn",
        "outputId": "327c955d-1955-42c6-ddeb-ae689ffa8694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===> Creating optimizer...\n",
            "\n",
            "    Base learning rate:    3.0e-03\n",
            "    Number of milestones:     4\n",
            "\n",
            "\n",
            "===> Creating scheduler...\n",
            "\n",
            "Step | Milestone | LR\n",
            "-----------------------------\n",
            "   0 |         0 | 3.0e-03   \n",
            "-----------------------------\n",
            "   1 |    200000 | 7.2e-04   \n",
            "   2 |    400000 | 1.7e-04   \n",
            "   3 |    600000 | 4.1e-05   \n",
            "   4 |    800000 | 1.0e-05   \n",
            "\n",
            "Total number of iterations:    1000000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Instantiate optimizer with base learning rate\n",
        "print(\"\\n===> Creating optimizer...\\n\")\n",
        "print(f\"    Base learning rate: {config('base_lr'):10.1e}\")\n",
        "optimizer = torch.optim.Adam(pinn_soln.parameters(), lr=config('base_lr'))\n",
        "\n",
        "# Learning rate milestones (after n_step iterations)\n",
        "n_milestones = config('num_steps') - 1\n",
        "print(f'    Number of milestones: {n_milestones:5d}\\n')\n",
        "milestones = [n * config('num_iters_per_step') for n in range(config('num_steps'))]\n",
        "\n",
        "print(\"\\n===> Creating scheduler...\\n\")\n",
        "# Drop first entry of milestones list because it contains the base LR\n",
        "scheduler = MultiStepLR(optimizer, milestones=milestones[1:], gamma=config('gamma'))\n",
        "\n",
        "mlp.print_milestones_and_lrs(config('base_lr'),\n",
        "                             config('num_steps'),\n",
        "                             milestones,\n",
        "                             config('gamma'),\n",
        "                             n_max_iterations=config('num_iterations'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LRk5UjmIgIfN",
      "metadata": {
        "id": "LRk5UjmIgIfN"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WuuGvgso_dR1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuuGvgso_dR1",
        "outputId": "fbf79769-a060-4186-defd-923d5330bcf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py:829: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:179.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iteration        0]  LR:  3.0e-03  |  Iter/s:   1.0  |  Time: 00:00:01\n",
            "   └── Cost [Train / Val / Best Val]:  3.148e-02  /  3.137e-02  /  3.137e-02\n",
            "[Iteration     2000]  LR:  3.0e-03  |  Iter/s: 124.1  |  Time: 00:00:16\n",
            "   └── Cost [Train / Val / Best Val]:  1.446e-05  /  1.426e-05  /  1.426e-05\n",
            "[Iteration     4000]  LR:  3.0e-03  |  Iter/s: 128.5  |  Time: 00:00:31\n",
            "   └── Cost [Train / Val / Best Val]:  8.343e-06  /  8.390e-06  /  8.390e-06\n",
            "[Iteration     6000]  LR:  3.0e-03  |  Iter/s: 129.9  |  Time: 00:00:46\n",
            "   └── Cost [Train / Val / Best Val]:  9.575e-06  /  1.003e-05  /  8.390e-06\n",
            "[Iteration     8000]  LR:  3.0e-03  |  Iter/s: 130.5  |  Time: 00:01:01\n",
            "   └── Cost [Train / Val / Best Val]:  2.498e-06  /  2.734e-06  /  2.734e-06\n",
            "[Iteration    10000]  LR:  3.0e-03  |  Iter/s: 131.0  |  Time: 00:01:16\n",
            "   └── Cost [Train / Val / Best Val]:  7.007e-06  /  6.932e-06  /  2.734e-06\n",
            "[Iteration    12000]  LR:  3.0e-03  |  Iter/s: 131.2  |  Time: 00:01:31\n",
            "   └── Cost [Train / Val / Best Val]:  6.122e-06  /  6.064e-06  /  2.734e-06\n",
            "[Iteration    14000]  LR:  3.0e-03  |  Iter/s: 131.3  |  Time: 00:01:46\n",
            "   └── Cost [Train / Val / Best Val]:  1.934e-06  /  1.987e-06  /  1.987e-06\n",
            "[Iteration    16000]  LR:  3.0e-03  |  Iter/s: 131.6  |  Time: 00:02:01\n",
            "   └── Cost [Train / Val / Best Val]:  5.366e-06  /  5.314e-06  /  1.987e-06\n",
            "[Iteration    18000]  LR:  3.0e-03  |  Iter/s: 131.8  |  Time: 00:02:16\n",
            "   └── Cost [Train / Val / Best Val]:  2.195e-06  /  2.246e-06  /  1.987e-06\n",
            "[Iteration    20000]  LR:  3.0e-03  |  Iter/s: 131.8  |  Time: 00:02:31\n",
            "   └── Cost [Train / Val / Best Val]:  3.027e-06  /  3.017e-06  /  1.987e-06\n"
          ]
        }
      ],
      "source": [
        "mlp.train_pinn(train_loader, val_loader, train_valsize_loader,\n",
        "               optimizer, scheduler, pinn_obj,\n",
        "               display_costs=live_display,\n",
        "               model_filename=config('file/params'),\n",
        "               log_filename=config('file/losses'),\n",
        "               plot_filename=config('file/plots'),\n",
        "               monitor_every_n_iterations=config('monitor_step'),\n",
        "               drop_threshold=config('val_cost_drop_threshold')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "644749ca-7e18-414a-bacf-1c0e82e3eacb",
      "metadata": {
        "id": "644749ca-7e18-414a-bacf-1c0e82e3eacb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}